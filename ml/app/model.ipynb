{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.8.0/ru_core_news_sm-3.8.0-py3-none-any.whl (15.3 MB)\n",
      "     ---------------------------------------- 0.0/15.3 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 1.0/15.3 MB 10.1 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 9.7/15.3 MB 33.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 15.3/15.3 MB 38.4 MB/s  0:00:00\n",
      "Collecting pymorphy3>=1.0.0 (from ru-core-news-sm==3.8.0)\n",
      "  Using cached pymorphy3-2.0.4-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting dawg2-python>=0.8.0 (from pymorphy3>=1.0.0->ru-core-news-sm==3.8.0)\n",
      "  Using cached dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pymorphy3-dicts-ru (from pymorphy3>=1.0.0->ru-core-news-sm==3.8.0)\n",
      "  Using cached pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: setuptools>=68.2.2 in c:\\users\\me\\dev\\python\\x5case\\ml\\.venv\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.8.0) (80.9.0)\n",
      "Using cached pymorphy3-2.0.4-py3-none-any.whl (54 kB)\n",
      "Using cached dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n",
      "Using cached pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
      "Installing collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3, ru-core-news-sm\n",
      "\n",
      "   -------------------- ------------------- 2/4 [pymorphy3]\n",
      "   ------------------------------ --------- 3/4 [ru-core-news-sm]\n",
      "   ---------------------------------------- 4/4 [ru-core-news-sm]\n",
      "\n",
      "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.4 pymorphy3-dicts-ru-2.4.417150.4580142 ru-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.prefer_gpu() # Используется ли ускорение на gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"\"\"Используйте трансформерные модели, если нужна максимальная нагрузка на GPU\n",
    "Стандартные маленькие модели (_sm) часто не используют GPU по полной, для максимума берите _trf версии \n",
    "(например, ru_core_news_trf), которые построены на PyTorch и используют CUDA для ускорения.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs: ['использовать', 'использовать', 'брать', 'построить', 'использовать']\n"
     ]
    }
   ],
   "source": [
    "# Analyze syntax\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = r\"data\\train.csv\"\n",
    "df = pd.read_csv(path_to_train, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертация датасета csv в spacy формат\n",
    "import ast\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "output_path = \"data/train.spacy\"\n",
    "\n",
    "db = DocBin()\n",
    "\n",
    "for (text, annotations_str) in df.to_numpy():\n",
    "    # перевод \"python code\" -> python code\n",
    "    annotations = ast.literal_eval(annotations_str)\n",
    "\n",
    "    end_text = len(text)\n",
    "\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations:\n",
    "        # Нужно изменить alignment_mode, тк есть опечатки в датасете + небольшие корректировки разметки\n",
    "        end = end_text if end > end_text else end\n",
    "        start = 0 if start < 0 else start\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"expand\")\n",
    "        ents.append(span)\n",
    "\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "\n",
    "db.to_disk(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример считывания из spacy файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные из файла\n",
    "with open(r\"data\\train.spacy\", \"rb\") as f:\n",
    "    doc_bin_bytes = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocBin().from_bytes(doc_bin_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(db.get_docs(nlp.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "стиральный  порош\n",
      "стиральный   B-TYPE\n",
      "порош I-TYPE\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    if doc.text == \"стиральный  порош\":\n",
    "        print(doc.text)\n",
    "        # Можно получить сущности, токены и др.\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
