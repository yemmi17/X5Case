{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.8.0/ru_core_news_lg-3.8.0-py3-none-any.whl (513.4 MB)\n",
      "     ---------------------------------------- 0.0/513.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.3/513.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.3/513.4 MB 4.2 MB/s eta 0:02:03\n",
      "     ---------------------------------------- 2.4/513.4 MB 4.6 MB/s eta 0:01:51\n",
      "     ---------------------------------------- 3.9/513.4 MB 5.5 MB/s eta 0:01:34\n",
      "     ---------------------------------------- 5.8/513.4 MB 6.2 MB/s eta 0:01:23\n",
      "      --------------------------------------- 7.9/513.4 MB 7.1 MB/s eta 0:01:12\n",
      "      -------------------------------------- 10.2/513.4 MB 7.8 MB/s eta 0:01:05\n",
      "     - ------------------------------------- 13.4/513.4 MB 8.8 MB/s eta 0:00:57\n",
      "     - ------------------------------------- 16.8/513.4 MB 9.8 MB/s eta 0:00:51\n",
      "     - ------------------------------------ 21.2/513.4 MB 11.1 MB/s eta 0:00:45\n",
      "     - ------------------------------------ 26.2/513.4 MB 12.3 MB/s eta 0:00:40\n",
      "     -- ----------------------------------- 32.5/513.4 MB 13.9 MB/s eta 0:00:35\n",
      "     -- ----------------------------------- 39.3/513.4 MB 15.3 MB/s eta 0:00:31\n",
      "     --- ---------------------------------- 46.4/513.4 MB 16.8 MB/s eta 0:00:28\n",
      "     ---- --------------------------------- 55.1/513.4 MB 18.6 MB/s eta 0:00:25\n",
      "     ---- --------------------------------- 61.6/513.4 MB 19.4 MB/s eta 0:00:24\n",
      "     ----- -------------------------------- 68.7/513.4 MB 20.4 MB/s eta 0:00:22\n",
      "     ----- -------------------------------- 75.5/513.4 MB 21.1 MB/s eta 0:00:21\n",
      "     ------ ------------------------------- 82.8/513.4 MB 21.8 MB/s eta 0:00:20\n",
      "     ------ ------------------------------- 91.8/513.4 MB 22.9 MB/s eta 0:00:19\n",
      "     ------- ------------------------------ 99.9/513.4 MB 23.7 MB/s eta 0:00:18\n",
      "     ------- ----------------------------- 106.7/513.4 MB 24.1 MB/s eta 0:00:17\n",
      "     -------- ---------------------------- 115.6/513.4 MB 24.9 MB/s eta 0:00:17\n",
      "     -------- ---------------------------- 123.2/513.4 MB 25.4 MB/s eta 0:00:16\n",
      "     --------- --------------------------- 131.3/513.4 MB 26.0 MB/s eta 0:00:15\n",
      "     ---------- -------------------------- 139.5/513.4 MB 26.5 MB/s eta 0:00:15\n",
      "     ---------- -------------------------- 147.1/513.4 MB 26.9 MB/s eta 0:00:14\n",
      "     ----------- ------------------------- 155.5/513.4 MB 27.4 MB/s eta 0:00:14\n",
      "     ----------- ------------------------- 164.9/513.4 MB 28.0 MB/s eta 0:00:13\n",
      "     ------------ ------------------------ 173.0/513.4 MB 28.4 MB/s eta 0:00:12\n",
      "     ------------- ----------------------- 183.2/513.4 MB 29.1 MB/s eta 0:00:12\n",
      "     -------------- ---------------------- 195.3/513.4 MB 29.9 MB/s eta 0:00:11\n",
      "     -------------- ---------------------- 205.3/513.4 MB 30.6 MB/s eta 0:00:11\n",
      "     --------------- --------------------- 216.0/513.4 MB 31.2 MB/s eta 0:00:10\n",
      "     ---------------- -------------------- 226.2/513.4 MB 31.7 MB/s eta 0:00:10\n",
      "     ----------------- ------------------- 237.0/513.4 MB 32.3 MB/s eta 0:00:09\n",
      "     ----------------- ------------------- 249.0/513.4 MB 33.0 MB/s eta 0:00:09\n",
      "     ------------------ ------------------ 259.3/513.4 MB 33.5 MB/s eta 0:00:08\n",
      "     ------------------- ----------------- 270.0/513.4 MB 38.4 MB/s eta 0:00:07\n",
      "     -------------------- ---------------- 280.2/513.4 MB 41.1 MB/s eta 0:00:06\n",
      "     -------------------- ---------------- 291.2/513.4 MB 42.8 MB/s eta 0:00:06\n",
      "     --------------------- --------------- 298.8/513.4 MB 43.2 MB/s eta 0:00:05\n",
      "     ---------------------- -------------- 309.9/513.4 MB 44.0 MB/s eta 0:00:05\n",
      "     ----------------------- ------------- 320.3/513.4 MB 44.6 MB/s eta 0:00:05\n",
      "     ----------------------- ------------- 329.8/513.4 MB 45.1 MB/s eta 0:00:05\n",
      "     ------------------------ ------------ 340.5/513.4 MB 45.9 MB/s eta 0:00:04\n",
      "     ------------------------- ----------- 351.8/513.4 MB 46.7 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 362.3/513.4 MB 47.2 MB/s eta 0:00:04\n",
      "     -------------------------- ---------- 373.0/513.4 MB 48.3 MB/s eta 0:00:03\n",
      "     --------------------------- --------- 384.8/513.4 MB 49.0 MB/s eta 0:00:03\n",
      "     ---------------------------- -------- 396.9/513.4 MB 49.9 MB/s eta 0:00:03\n",
      "     ----------------------------- ------- 408.9/513.4 MB 51.1 MB/s eta 0:00:03\n",
      "     ------------------------------ ------ 420.0/513.4 MB 51.7 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 428.9/513.4 MB 52.1 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 438.3/513.4 MB 52.1 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 449.6/513.4 MB 52.5 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 459.3/513.4 MB 52.4 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 470.5/513.4 MB 52.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 482.9/513.4 MB 52.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 494.4/513.4 MB 52.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  505.9/513.4 MB 52.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  513.3/513.4 MB 52.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  513.3/513.4 MB 52.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 513.4/513.4 MB 48.4 MB/s  0:00:13\n",
      "Requirement already satisfied: pymorphy3>=1.0.0 in c:\\users\\me\\dev\\python\\x5case\\ml\\.venv\\lib\\site-packages (from ru-core-news-lg==3.8.0) (2.0.4)\n",
      "Requirement already satisfied: dawg2-python>=0.8.0 in c:\\users\\me\\dev\\python\\x5case\\ml\\.venv\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.8.0) (0.9.0)\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in c:\\users\\me\\dev\\python\\x5case\\ml\\.venv\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.8.0) (2.4.417150.4580142)\n",
      "Requirement already satisfied: setuptools>=68.2.2 in c:\\users\\me\\dev\\python\\x5case\\ml\\.venv\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-lg==3.8.0) (70.2.0)\n",
      "Installing collected packages: ru-core-news-lg\n",
      "Successfully installed ru-core-news-lg-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!uv run spacy download ru_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.prefer_gpu() # Используется ли ускорение на gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"\"\"Используйте трансформерные модели, если нужна максимальная нагрузка на GPU\n",
    "Стандартные маленькие модели (_sm) часто не используют GPU по полной, для максимума берите _trf версии \n",
    "(например, ru_core_news_trf), которые построены на PyTorch и используют CUDA для ускорения.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs: ['использовать', 'использовать', 'брать', 'построить', 'использовать']\n"
     ]
    }
   ],
   "source": [
    "# Analyze syntax\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = r\"data\\train.csv\"\n",
    "df = pd.read_csv(path_to_train, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from spacy.tokens import DocBin\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_save(data_array, output_path):\n",
    "    # Создаем объект DocBin для сериализации документов spaCy\n",
    "    db = DocBin()\n",
    "    \n",
    "    # Проходим по всем строкам данных (каждая строка - текст и строка с аннотациями)\n",
    "    for (text, annotations_str) in data_array:\n",
    "        # Преобразуем строковое представление аннотаций в Python-объект (список кортежей)\n",
    "        annotations = ast.literal_eval(annotations_str)\n",
    "\n",
    "        end_text = len(text)  # Длина текста для корректировки границ сущностей\n",
    "\n",
    "        # Создаем объект Doc из исходного текста (токенизация без анализа)\n",
    "        doc = nlp.make_doc(text)\n",
    "\n",
    "        ents = []\n",
    "        for start, end, label in annotations:\n",
    "            # Корректируем границы, чтобы не выходить за пределы текста\n",
    "            end = end_text if end > end_text else end\n",
    "            start = 0 if start < 0 else start\n",
    "            \n",
    "            # Создаем span - сегмент с меткой, с режимом расширения, чтобы избежать пропусков из-за ошибок разметки\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"expand\")\n",
    "            ents.append(span)\n",
    "\n",
    "        # Присваиваем полученные сущности документу\n",
    "        doc.ents = ents\n",
    "        \n",
    "        # Добавляем документ в объект DocBin (формат для эффективного хранения и обмена)\n",
    "        db.add(doc)\n",
    "\n",
    "    # Сохраняем сериализованный набор документов в файл на диск\n",
    "    db.to_disk(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь для сохранения обучающего датасета в формате spacy\n",
    "output_train_path = \"data/train.spacy\"\n",
    "# Путь для сохранения валидационного (dev) датасета\n",
    "output_dev_path = \"data/dev.spacy\"\n",
    "\n",
    "# Деление данных DataFrame на тренировочную и дев выборки в соотношении 0.7 к 0.3\n",
    "data = df.to_numpy()\n",
    "\n",
    "# Перемешиваем\n",
    "np.random.seed(42)\n",
    "shuffled_indices = np.random.permutation(len(data))\n",
    "data = data[shuffled_indices]\n",
    "\n",
    "split_idx = math.floor(len(data) * 0.7)  # Индекс, где делим массив\n",
    "\n",
    "# Разделяем данные\n",
    "train_data = data[:split_idx]  # 70% для тренировки\n",
    "dev_data = data[split_idx:]    # 30% для валидации\n",
    "\n",
    "# Конвертируем и сохраняем тренировочный датасет\n",
    "convert_and_save(train_data, output_train_path)\n",
    "# Конвертируем и сохраняем валидационный датасет\n",
    "convert_and_save(dev_data, output_dev_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример считывания из spacy файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные из файла\n",
    "with open(r\"data\\train.spacy\", \"rb\") as f:\n",
    "    doc_bin_bytes = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocBin().from_bytes(doc_bin_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(db.get_docs(nlp.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abon\n",
      "abon O\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    if doc.text == \"abon\":\n",
    "        print(doc.text)\n",
    "        # Можно получить сущности, токены и др.\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.tokens import DocBin\n",
    "\n",
    "# # Чтение и загрузка тренировочного файла\n",
    "# with open(r\"data/train.spacy\", \"rb\") as f:\n",
    "#     train_doc_bin_bytes = f.read()\n",
    "\n",
    "# train_db = DocBin().from_bytes(train_doc_bin_bytes)\n",
    "\n",
    "# # Чтение и загрузка валидирующего файла\n",
    "# with open(r\"data/dev.spacy\", \"rb\") as f:\n",
    "#     dev_doc_bin_bytes = f.read()\n",
    "\n",
    "# dev_db = DocBin().from_bytes(dev_doc_bin_bytes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тест обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"models_gpu/model-last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(r\"абрикосы 500г global village\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"фруктовое пбре без сахара\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "абрикосы B-TYPE\n",
      "500 B-BRAND\n",
      "г I-BRAND\n",
      "global B-BRAND\n",
      "village I-BRAND\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
